#!/usr/bin/env ruby

$stdout.sync = $stderr.sync = true

require "bundler/setup"
Bundler.require

require_relative "../lib/black_swan"

DB = Sequel.connect(BlackSwan::Config.database_url)

def process_page(options={})
  new = 0
  res = Excon.get(
    "https://api.twitter.com/1/statuses/user_timeline.json",
    expects: 200,
    query: {
      max_id:      options[:max_id],
      screen_name: BlackSwan::Config.twitter_handle,
      since_id:    options[:since_id],
    }.reject { |k, v| v == nil })
  events = MultiJson.decode(res.body)
  events.each do |event|
    next if DB[:events].first(slug: event["id"].to_s) != nil

    new += 1
    content = event["text"]

    # axe Twitter's crappy shortlinks
    if event["entities"]
      event["entities"]["urls"].each do |url|
        if url["expanded_url"]
          content.sub!(url["url"], url["expanded_url"])
        end
      end
    end

    DB[:events].insert(
      content:     content,
      occurred_at: event["created_at"],
      slug:        event["id"].to_s,
      metadata: {
        mention:   (content =~ /^\s*@/) != nil,
        permalink: "https://twitter.com/#{BlackSwan::Config.twitter_handle}" +
          "/statuses/#{event["id"]}",
      }.hstore)
  end

  [new, events]
end

puts "updating"
latest = DB[:events].max("slug::bigint".lit)
begin
  new, events = process_page(since_id: latest)
  puts "processed=#{new} latest=#{latest}"
  latest = events.count > 0 ? events.max_by { |e| e["id"] }["id"] : nil
end while new > 0

puts "backfilling"
earliest = DB[:events].min("slug::bigint".lit)
begin
  new, events = process_page(max_id: earliest)
  puts "processed=#{new} earliest=#{earliest}"
  earliest = events.count > 0 ? events.min_by { |e| e["id"] }["id"] : nil
end while new > 0
